Title: Polyhedral decomposition of Feed-Forward ReLU Neural Networks

Speaker: Vicente Bosca

Abstract: This talk will serve as a survey of the literature I have been reading this past summer. They revolve around feedforward ReLU neural networks, and how the introduction of that piecewise nonlinear function between layers partitions the input space into convex polyhedra, where within each of them, the neural network is defined by an affine function. We will start by reviewing the paper by Liu et al.  "ReLU Neural Networks, Polyhedral Decompositions, and Persistent Homology", where they explicitly construct these polyhedra. I will briefly mention how they use homology, and then move to a paper by some of the same authors where they explicitly construct the linear maps within each polyhedral region. We will go over some available algorithms and libraries to visualize and compute this polyhedral decomposition, and mention some results on how many of these regions we can encounter. We will end up relating this to some other concepts in machine learning, like grokking or adversarial examples. Time permitting, I will display some other papers that intersect this topic with topology and geometry.
